---
layout: page
permalink: /publications/index.html
title: Publications
---

- [AtRec: Accelerating Recommendation Model Training on CPUs](https://ieeexplore.ieee.org/abstract/document/10478579)
<br>
Siqi Wang\*, **Tianyu Feng\***, Hailong Yang, Xin You, Bangduo Chen, Tongxuan Liu, Zhongzhi Luan, Depei Qian
<br>
\*Equal contribution.
<br>
[TPDS 2024] IEEE Transactions on Parallel and Distributed Systems
<br>
[[source code](https://github.com/buaa-hipo/Atrec)]
[[html](https://ieeexplore.ieee.org/abstract/document/10478579)]
[[pdf](https://fty1777.github.io/file/AtRec.pdf)]
(Early Access)

- [dgQuEST: Accelerating Large Scale Quantum Circuit Simulation through Hybrid CPU-GPU Memory Hierarchies](https://link.springer.com/chapter/10.1007/978-3-030-93571-9_2)
<br>
**Tianyu Feng**, Siyan Chen, Xin You, Shuzhang Zhong, Hailong Yang, Zhongzhi Luan, Depei Qian
<br>
[NPC 2021, **Best Paper**] Network and Parallel Computing: 18th IFIP WG 10.3 International Conference
<br>
[[source code](https://github.com/fty1777/dgQuEST)]
[[html](https://link.springer.com/chapter/10.1007/978-3-030-93571-9_2)]
[[pdf](https://fty1777.github.io/file/dgQuEST.pdf)]

- [Exploiting Input Tensor Dynamics in Activation Checkpointing for Efficient Training on GPU](https://ieeexplore.ieee.org/abstract/document/10177427)
<br>
Jianjin Liao, Mingzhen Li, Hailong Yang, Qingxiao Sun, Biao Sun, Jiwei Hao, **Tianyu Feng**, Fengwei Yu, Shengdong Chen, Ye Tao, Zicheng Zhang, Zhongzhi Luan, Depei Qian
<br>
2023 IEEE International Parallel and Distributed Processing Symposium [IPDPS 23]
<br>
[[source code](https://zenodo.org/records/7656850)]
[[html](https://ieeexplore.ieee.org/abstract/document/10177427)]
[[pdf](https://fty1777.github.io/file/mimose.pdf)]

- [Minions: Accelerating Large Language Model Inference with Adaptive and Collective Speculative Decoding](https://arxiv.org/abs/2402.15678)
<br>
Siqi Wang, Hailong Yang, Xuezhu Wang, Tongxuan Liu, Pengbo Wang, Xuning Liang, Kejie Ma, **Tianyu Feng**, Xin You, Yongjun Bao, Yi Liu, Zhongzhi Luan, Depei Qian
<br>
arXiv 2024
<br>
[[html](https://arxiv.org/abs/2402.15678)]
[[pdf](https://arxiv.org/pdf/2402.15678)]
